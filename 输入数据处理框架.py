import tensorflow as tf
files=tf.train.match_filenames_once('./data_/file_pattern-*')
filename_queue=tf.train.string_input_producer(files,shuffle=False)
reader=tf.TFRecordReader()
_,serialized_example=reader.read(filename_queue)
features=tf.train.Features(
    serialized_example,
    features={
        'image':tf.FixedLenFeature([],tf.string),#图像原始数据
        'label':tf.FixedLenFeature([],tf.int64),#图像标签
        'height':tf.FixedLenFeature([],tf.int64),#一下三个为图像的维度
        'weight':tf.FixedLenFeature([],tf.int64),
        'channels':tf.FixedLenFeature([],tf.int64),
    }
)
image,label=features['image'],features['label']
height,weight=features['weight'],features['weight']
channels=features['channels']
#从原始图像解析出像素矩阵，并根据图像尺寸还原图像
decode_image=tf.decode_raw(image,tf.uint8)
decode_image.set_shape([height,weight,channels])
#定义神经网络输入层图片的大小
image_size=299
distorted_image=preprocess_for_train(
    decode_image,image_size,image_size,None
)
min_after_dequeue=10000
batch_size=100
capacity=min_after_dequeue+3*batch_size
image_batch,label_batch=tf.train.shuffle_batch(
    [distorted_image,label],batch_size=batch_size,min_after_dequeue=min_after_dequeue
)
logit=inference(image_batch)
loss=calc_loss(logit,label_batch)
train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)
with tf.Sessio() as s:
    s.run(tf.global_variables_initializer())
    coord=tf.train.Coordinator()
    threads=tf.train.start_queue_runners(sess=s,coord=coord)
    for i in range(TRAINING_ROUNDS):
        s.run(train_step)
    coord.request_stop()
    coord.join(threads)